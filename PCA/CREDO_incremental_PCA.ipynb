{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T08:23:30.683814Z",
     "start_time": "2025-09-23T08:23:17.880853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "##########################################\n",
    "# Comparision of PCA and PCA incremental PCA\n",
    "# Author: Tomasz Hachaj\n",
    "# e-mail: thachaj@agh.edu.pl\n",
    "# 2025\n",
    "##########################################\n",
    "\n",
    "import numpy as np\n",
    "path_to_data = 'data'\n",
    "how_many_images = 3500\n",
    "T = np.load(path_to_data + \"//CREDO_T_st_\" + str(how_many_images) + \".npy\").transpose()\n",
    "\n",
    "path_to_resultspartial = 'pca.res_CREDO'\n",
    "\n",
    "batch_size=1000\n",
    "start = 0\n",
    "end = 0\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "#transformer = IncrementalPCA(n_components=T.shape[1], batch_size=batch_size)\n",
    "# n_components must be less or equal to the batch number of samples 1000 for the first partial_fit call\n",
    "transformer = IncrementalPCA(n_components=1000, batch_size=batch_size)\n",
    "\n",
    "a = 0\n",
    "\n",
    "while end < T.shape[0]:\n",
    "    end = start + batch_size\n",
    "    if end > T.shape[0]:\n",
    "        end = T.shape[0]\n",
    "    bb = T[start:end:]\n",
    "    transformer.partial_fit(bb)\n",
    "\n",
    "    my_path = path_to_resultspartial + '/pickle' + str(start) + '-' + str(end) + '.pkl'\n",
    "    with open(my_path, 'wb') as outp:\n",
    "        pickle.dump(transformer, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    transformer = None\n",
    "\n",
    "    with open(my_path, 'rb') as inp:\n",
    "        transformer = pickle.load(inp)\n",
    "\n",
    "    start = end\n",
    "    print(str(a) + \" of \" + str(int(T.shape[0] / batch_size)))\n",
    "    a = a + 1"
   ],
   "id": "a922e783bc60999e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 3\n",
      "1 of 3\n",
      "2 of 3\n",
      "3 of 3\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T08:24:34.404203Z",
     "start_time": "2025-09-23T08:24:11.223947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# path to results computed with PCA\n",
    "# Author: Tomasz Hachaj\n",
    "# e-mail: tomekhachaj@o2.pl\n",
    "# 2023\n",
    "##########################################\n",
    "# Comparison of coordinate frames obtained with basic PCA to coordinate frames obtained with Incremental PCA\n",
    "# for a different number of data used when approximating PCA\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def correct_vector(v1):\n",
    "    v_help = np.copy(v1)\n",
    "    max_val = np.max(v_help)\n",
    "    min_val = np.min(v_help)\n",
    "    if np.abs(min_val) > np.abs(max_val) and min_val < 0:\n",
    "        v_help *= -1\n",
    "    return v_help\n",
    "\n",
    "import math\n",
    "def planar_angle(v1, v2):\n",
    "    unit_vector_1 = v1 / np.linalg.norm(v1)\n",
    "    unit_vector_2 = v2 / np.linalg.norm(v2)\n",
    "    dot_product = np.dot(unit_vector_1, unit_vector_2)\n",
    "    if dot_product < -1:\n",
    "        dot_product = -1\n",
    "    if dot_product > 1:\n",
    "        dot_product = 1\n",
    "    angle = np.arccos(dot_product)\n",
    "    if math.isnan(angle):\n",
    "        angle = 0\n",
    "    return angle\n",
    "\n",
    "\n",
    "# path to results computed with PCA\n",
    "path_to_results = \"pca.res_CREDO//\"\n",
    "# path to results computed with Incremental PCA\n",
    "# path to store results\n",
    "file = open('axes_similarityPCA.txt', 'w')\n",
    "\n",
    "#start = 560000\n",
    "#end =  570000\n",
    "start = 0\n",
    "end =  1000\n",
    "how_many_images = 3500\n",
    "\n",
    "v_correct = np.load(path_to_results + \"//CREDO_v_st_\" + str(how_many_images) + \".npy\")\n",
    "w = np.load(path_to_results + \"//CREDO_w_st_\" + str(how_many_images) + \".npy\")\n",
    "v_correct_scalled = w / np.sum(w)\n",
    "\n",
    "transformer = None\n",
    "\n",
    "while end < T.shape[0]:\n",
    "    end = start + batch_size\n",
    "    if end > T.shape[0]:\n",
    "        end = T.shape[0]\n",
    "    my_path = path_to_resultspartial + '//pickle' + str(start) + '-' + str(end) + '.pkl'\n",
    "    with open(my_path, 'rb') as inp:\n",
    "        transformer = pickle.load(inp)\n",
    "    cumulatice_sum = 0\n",
    "    sum_angle_res = 0\n",
    "    # calculation of coordinate frames weighted distance (cfd)\n",
    "    #for a in range(v_correct.shape[1]):\n",
    "    for a in range(min(v_correct.shape[1], transformer.components_.shape[0])):\n",
    "        v_help1 = correct_vector(v_correct[:, a])\n",
    "        #print(transformer.components_.shape)\n",
    "        v_help2 = correct_vector(transformer.components_[a, :])\n",
    "        angle_res = planar_angle(v_help1, v_help2)\n",
    "        average_eigen = (v_correct_scalled[a] + transformer.explained_variance_ratio_[a]) / 2\n",
    "        cumulatice_sum += average_eigen\n",
    "        sum_angle_res += average_eigen * angle_res\n",
    "    print(str(start) + \",\" + str(end) + \",\" + str(sum_angle_res))\n",
    "    start = end\n",
    "    #file.write(str(start) + \",\" + str(end) + \",\" + str(sum_angle_res) + '\\n')"
   ],
   "id": "81a7c850313ffffa",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     44\u001B[39m end =  \u001B[32m1000\u001B[39m\n\u001B[32m     45\u001B[39m how_many_images = \u001B[32m3500\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m v_correct = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_to_results\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m//CREDO_v_st_\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhow_many_images\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m.npy\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m w = np.load(path_to_results + \u001B[33m\"\u001B[39m\u001B[33m//CREDO_w_st_\u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mstr\u001B[39m(how_many_images) + \u001B[33m\"\u001B[39m\u001B[33m.npy\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     49\u001B[39m v_correct_scalled = w / np.sum(w)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\Python\\PycharmProjects\\TestNaKursPotenUsun\\.venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[39m\n\u001B[32m    453\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m.open_memmap(file, mode=mmap_mode,\n\u001B[32m    454\u001B[39m                                   max_header_size=max_header_size)\n\u001B[32m    455\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    457\u001B[39m \u001B[43m                                 \u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m                                 \u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    459\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    460\u001B[39m     \u001B[38;5;66;03m# Try a pickle\u001B[39;00m\n\u001B[32m    461\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\Python\\PycharmProjects\\TestNaKursPotenUsun\\.venv\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001B[39m, in \u001B[36mread_array\u001B[39m\u001B[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001B[39m\n\u001B[32m    806\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m isfileobj(fp):\n\u001B[32m    808\u001B[39m         \u001B[38;5;66;03m# We can use the fast fromfile() function.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m809\u001B[39m         array = \u001B[43mnumpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfromfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcount\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    810\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    811\u001B[39m         \u001B[38;5;66;03m# This is not a real file. We have to read it the\u001B[39;00m\n\u001B[32m    812\u001B[39m         \u001B[38;5;66;03m# memory-intensive way.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    820\u001B[39m         \u001B[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001B[39;00m\n\u001B[32m    821\u001B[39m         \u001B[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001B[39;00m\n\u001B[32m    822\u001B[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
